<!doctype html>
<html lang="ja">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>ã‚¤ãƒã‚¸ãƒ³ã•ã‚“ AIã€€ãƒ–ãƒãƒ¥ãƒ–ãƒãƒ¥ãƒãƒ³ã¾ãŸã¯ã¶ã¤ã¶ã¤ãƒãƒ³ Voice Assistant (è‡ªå‹•é€£ç¶šèªè­˜ + VAD)</title>
<style>
/* CSSéƒ¨åˆ†ã¯å¤‰æ›´ãªã— */
    :root{--accent:#00ffff;--accent-2:#00ffaa;--bg:#0f0f0f}
    html,body{height:100%;margin:0;background:var(--bg);color:#fff;font-family:Segoe UI,system-ui,Arial}
    canvas{position:fixed;inset:0;z-index:0}
    
    /* ğŸ’¡ UIã®ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆã¨ã‚¿ãƒƒãƒ—é ˜åŸŸã®ã‚¹ã‚¿ã‚¤ãƒ« */
    #ui{
        position:absolute;left:50%;bottom:5%;transform:translateX(-50%);z-index:10;width:min(980px,94vw);
        opacity: 1; /* åˆæœŸè¡¨ç¤º */
        transition: opacity 0.5s ease-in-out; /* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š */
    }
    /* ç”»é¢å…¨ä½“ã‚’ã‚¿ãƒƒãƒ—é ˜åŸŸã¨ã—ã¦è¨­å®š */
    #tapArea {
        position: fixed;
        inset: 0;
        z-index: 5; /* UIã®ä¸‹ã€ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ä¸Šã«é…ç½® */
    }

    #status-area{padding:14px 20px;border-radius:12px;background:rgba(0,0,0,0.45);box-shadow:0 0 20px #00ffff55;color:var(--accent);font-weight:700}
    #controls{display:flex;gap:12px;margin-top:10px;align-items:center}
    #messageInput{flex:1;padding:12px 14px;border-radius:10px;border:1px solid rgba(0,255,255,0.15);background:rgba(255,255,255,0.03);color:#fff;font-size:16px}
    button{padding:10px 14px;border-radius:10px;border:none;cursor:pointer;font-weight:700}
    #micBtn{background:var(--accent-2);color:#000} /* ã“ã®ãƒœã‚¿ãƒ³ã¯æ©Ÿèƒ½çš„ã«ã¯ä½¿ã‚ãªã„ãŒã€CSSã¯æ®‹ã™ */
    #resetBtn{background:var(--accent);color:#000}
    #modeIndicator{padding:8px 10px;border-radius:8px;background:#00000044;font-size:0.9rem}
    #subtext{margin-top:8px;color:#bfeeff}
    .active{box-shadow:0 0 20px #ff5555}
    #transcript{margin-top:12px;padding:12px;border-radius:10px;background:rgba(255,255,255,0.02);min-height:48px;font-size:16px}
</style>
</head>
<body>
<canvas id="waveCanvas"></canvas>

<div id="tapArea"></div>

<div id="ui">
    <div id="status-area">Initializing...</div>
    <div id="controls">
        <input id="messageInput" placeholder="è©±ã—ã‹ã‘ã¦ãã ã•ã„..." disabled> <button id="resetBtn">ãƒªã‚»ãƒƒãƒˆ</button>
        <div id="modeIndicator">STT/LLM/IoT</div>
    </div>
    <div id="subtext">é€£ç¶šèªè­˜ãƒ¢ãƒ¼ãƒ‰ï¼ˆVADã«ã‚ˆã‚‹è‡ªå‹•ã‚¹ã‚¿ãƒ¼ãƒˆ/ã‚¹ãƒˆãƒƒãƒ—ï¼‰</div>
    <div id="transcript"></div>
</div><script>
// Canvasç’°å¢ƒã§ã¯è‡ªå‹•ã§APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã™ãŒã€ã“ã“ã§ã¯FastAPIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ãŸã‚ã€ç©ºã®ã¾ã¾ã«ã—ã¾ã™ã€‚
const API_KEY = ""; 
// const GEMINI_MODEL = 'gemini-2.5-flash-preview-09-2025'; // ä¸è¦ (ã‚µãƒ¼ãƒãƒ¼å´ã§å®šç¾©)
// ğŸ’¡ LLM FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®URL (gemini_backend.py ãŒãƒãƒ¼ãƒˆ8001ã§å‹•ä½œ)
const LLM_API_URL = "http://127.0.0.1:8001/generate";
// ğŸ’¡ MQTT FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®URL (iot_backend.py ãŒãƒãƒ¼ãƒˆ8000ã§å‹•ä½œ)
const MQTT_API_URL = "http://127.0.0.1:8000/control"; 

/* ---------- DOM ---------- */
const statusArea = document.getElementById('status-area');
const resetBtn = document.getElementById('resetBtn');
const input = document.getElementById('messageInput');
const modeIndicator = document.getElementById('modeIndicator');
const transcriptBox = document.getElementById('transcript');
const ui = document.getElementById('ui'); 
const tapArea = document.getElementById('tapArea'); 

/* ---------- Audio / Waveform ---------- */
const canvas = document.getElementById('waveCanvas');
const ctx = canvas.getContext('2d');
function resizeCanvas(){canvas.width = innerWidth; canvas.height = innerHeight}
window.addEventListener('resize', resizeCanvas); resizeCanvas();

let audioContext, analyser, mediaStream;
let isRecording = false; // éŸ³å£°èªè­˜ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ã©ã†ã‹
let recognition = null; // Web Speech API SpeechRecognition Object

/* ---------- UI helpers ---------- */
function status(msg){ statusArea.textContent = msg }

/* ---------- Speech Recognition (Browser STT) & Audio Init ---------- */

/**
Â * Web Speech APIã«ã‚ˆã‚‹éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ã€‚
Â * ã“ã®é–¢æ•°ã¯ã€ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæˆåŠŸã—ã€audioContextãŒæº–å‚™ã§ãã¦ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
Â */
function startBrowserRecognition() {
Â  Â  // æ—¢ã«å®Ÿè¡Œä¸­ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
Â  Â  if (isRecording) return;
Â  Â  
Â  Â  if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
Â  Â  Â  Â  status('Error: Speech Recognition not supported in this browser.');
Â  Â  Â  Â  return;
Â  Â  }

Â  Â  // æ—¢å­˜ã®èªè­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¯ãƒªã‚¢
Â  Â  if (recognition) {
Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  recognition = null;
Â  Â  }

Â  Â  recognition = new (window.webkitSpeechRecognition || window.SpeechRecognition)();

Â  Â  // é€£ç¶šèªè­˜ãƒ¢ãƒ¼ãƒ‰ (ç™ºè©±ã®åˆ‡ã‚Œç›®ã§è‡ªå‹•åœæ­¢)
Â  Â  recognition.continuous = false; 
Â  Â  recognition.interimResults = true; 
Â  Â  recognition.lang = 'ja-JP';

Â  Â  recognition.onstart = () => {
Â  Â  Â  Â  isRecording = true;
Â  Â  Â  Â  status('Listening...');
Â  Â  Â  Â  input.value = 'è©±ã—ã¦ã„ã¾ã™...';
Â  Â  };

Â  Â  recognition.onresult = (event) => {
Â  Â  Â  Â  let interimTranscript = '';
Â  Â  Â  Â  let finalTranscript = '';

Â  Â  Â  Â  for (let i = event.resultIndex; i < event.results.length; ++i) {
Â  Â  Â  Â  Â  Â  if (event.results[i].isFinal) {
Â  Â  Â  Â  Â  Â  Â  Â  finalTranscript += event.results[i][0].transcript;
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  interimTranscript += event.results[i][0].transcript;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }

Â  Â  Â  Â  transcriptBox.textContent = finalTranscript || interimTranscript;
Â  Â  Â  Â  input.value = finalTranscript || interimTranscript;
Â  Â  };

Â  Â  // ğŸ’¡ ç™ºè©±çµ‚äº†ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•å†ã‚¹ã‚¿ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯
Â  Â  const restartRecognition = () => {
Â  Â  Â  Â  status('Recognition stopped. Restarting...');
Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.start();
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  // æ—¢ã«å®Ÿè¡Œä¸­ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–
Â  Â  Â  Â  Â  Â  Â  Â  if (e.name !== 'InvalidStateError') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.warn('Recognition start failed:', e);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }, 500); 
Â  Â  };
Â  Â  
Â  Â  recognition.onend = () => {
Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  
Â  Â  Â  Â  const finalPrompt = transcriptBox.textContent.trim();
Â  Â  Â  Â  
Â  Â  Â  Â  if (finalPrompt && finalPrompt.length > 1 && !finalPrompt.startsWith("ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”:")) { // çŸ­ã™ãã‚‹ç™ºè©±ã‚„AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ç„¡è¦–
Â  Â  Â  Â  Â  Â  status('Processing response...');
Â  Â  Â  Â  Â  Â  processRecognitionResult(finalPrompt).finally(() => {
Â  Â  Â  Â  Â  Â  Â  Â  restartRecognition(); // å‡¦ç†å¾Œã«å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  // èªè­˜çµæœãŒãªã„å ´åˆã¯å³åº§ã«å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  Â  Â  Â  Â  transcriptBox.textContent = '';
Â  Â  Â  Â  Â  Â  input.value = 'è©±ã—ã‹ã‘ã¦ãã ã•ã„...';
Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  }
Â  Â  };

Â  Â  recognition.onerror = (event) => {
Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  console.error('Speech Recognition Error:', event.error);
Â  Â  Â  Â  
Â  Â  Â  Â  // ğŸ’¡ ä¿®æ­£ç®‡æ‰€: 'aborted' ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚å†ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
Â  Â  Â  Â  if (event.error !== 'no-speech' && event.error !== 'aborted') {
Â  Â  Â  Â  Â  Â  // 'not-allowed', 'audio-capture' ãªã©ã®ã‚¨ãƒ©ãƒ¼ã§å†ã‚¹ã‚¿ãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  } else if (event.error === 'no-speech' || event.error === 'network' || event.error === 'aborted') {
Â  Â  Â  Â  Â  Â  // ç„¡éŸ³ã‚¨ãƒ©ãƒ¼ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã€ã¾ãŸã¯è‡ªå‹•ä¸­æ–­ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€UIã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  Â  Â  Â  Â  transcriptBox.textContent = '';
Â  Â  Â  Â  Â  Â  input.value = 'è©±ã—ã‹ã‘ã¦ãã ã•ã„...';
Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  }
Â  Â  Â  Â  // 'not-allowed'ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆãƒã‚¤ã‚¯è¨±å¯ãŒãªã„ãŸã‚ï¼‰
Â  Â  };

Â  Â  // æœ€åˆã®ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  try {
Â  Â  Â  Â  recognition.start();
Â  Â  } catch (e) {
Â  Â  Â  Â  console.warn('Initial recognition start failed:', e);
Â  Â  }
}

/**
Â * ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚ã—ã€AudioContextã€æ³¢å½¢åˆ†æã€ãŠã‚ˆã³STTã‚’è¨­å®šã™ã‚‹
Â */
async function initAudioAndSTT(){
Â  Â  // æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯STTã ã‘å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  if(analyser) {
Â  Â  Â  Â  startBrowserRecognition();
Â  Â  Â  Â  return;
Â  Â  }
Â  Â  status('Requesting microphone access...');

Â  Â  try {
Â  Â  Â  Â  // 1. AudioContextã®åˆæœŸåŒ–
Â  Â  Â  Â  audioContext = new (window.AudioContext || window.webkitAudioContext)();
Â  Â  Â  Â  analyser = audioContext.createAnalyser();
Â  Â  Â  Â  analyser.fftSize = 2048;
Â  Â  Â  Â  
Â  Â  Â  Â  // 2. ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
Â  Â  Â  Â  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
Â  Â  Â  Â  const sourceNode = audioContext.createMediaStreamSource(mediaStream);
Â  Â  Â  Â  
Â  Â  Â  Â  // 3. æ¥ç¶šï¼ˆã‚½ãƒ¼ã‚¹ -> ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ï¼‰
Â  Â  Â  Â  sourceNode.connect(analyser);

Â  Â  Â  Â  // 4. ãƒ–ãƒ©ã‚¦ã‚¶STTã®é–‹å§‹
Â  Â  Â  Â  startBrowserRecognition();

Â  Â  Â  Â  status('Listening...');
Â  Â  } catch (e) {
Â  Â  Â  Â  console.error('Audio initialization failed:', e);
Â  Â  Â  Â  status('Error: Microphone access denied or failed to initialize.');
Â  Â  }
}

/**
Â * ğŸ’¡ æ–°è¦è¿½åŠ : FastAPI/MQTTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡ã™ã‚‹é–¢æ•°
Â */
async function sendIoTCommand(command) {
Â  Â  status(`Executing IoT command: ${command}...`);
Â  Â  transcriptBox.textContent = `IoTã‚³ãƒãƒ³ãƒ‰: ${command} ã‚’å®Ÿè¡Œä¸­...`;
Â  Â  
Â  Â  try {
Â  Â  Â  Â  const response = await fetch(MQTT_API_URL, {
Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  headers: {
Â  Â  Â  Â  Â  Â  Â  Â  'Content-Type': 'application/json'
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  body: JSON.stringify({ command: command })
Â  Â  Â  Â  });

Â  Â  Â  Â  const data = await response.json();

Â  Â  Â  Â  if (response.ok) {
Â  Â  Â  Â  Â  Â  // æˆåŠŸ
Â  Â  Â  Â  Â  Â  const successMsg = `æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚${command === 'ON' ? 'é›»æ°—ã‚’ã¤ã‘ã¾ã—ãŸ' : 'é›»æ°—ã‚’æ¶ˆã—ã¾ã—ãŸ'}ã€‚`;
Â  Â  Â  Â  Â  Â  console.log("IoT Success:", data);
Â  Â  Â  Â  Â  Â  speak(successMsg);
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  // å¤±æ•— (HTTP 4xx/5xx ã‚¨ãƒ©ãƒ¼)
Â  Â  Â  Â  Â  Â  const detail = data.detail || "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼";
Â  Â  Â  Â  Â  Â  const errorMsg = `ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚IoTã‚³ãƒãƒ³ãƒ‰ '${command}' ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: ${detail}`;
Â  Â  Â  Â  Â  Â  console.error("IoT Error:", data);
Â  Â  Â  Â  Â  Â  speak(errorMsg);
Â  Â  Â  Â  }
Â  Â  } catch (error) {
Â  Â  Â  Â  // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãªã©
Â  Â  Â  Â  const networkErrorMsg = `ğŸ”´ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: IoTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ (${error.message})`;
Â  Â  Â  Â  console.error("IoT Network Error:", error);
Â  Â  Â  Â  speak(networkErrorMsg);
Â  Â  }
}


/* ---------- çµ±åˆã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° (IoT or LLM) ---------- */

async function processRecognitionResult(finalPrompt) {
Â  Â  // 1. IoTã‚³ãƒãƒ³ãƒ‰ã®åˆ¤å®šã¨æŒ¯ã‚Šåˆ†ã‘
Â  Â  const lowerPrompt = finalPrompt.toLowerCase();
Â  Â  let iotCommand = null;

Â  Â  if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã¤ã‘') || lowerPrompt.includes('ã‚ªãƒ³') || lowerPrompt.includes('ç‚¹ã‘'))) {
Â  Â  Â  Â  iotCommand = 'ON';
Â  Â  } else if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã‘ã—') || lowerPrompt.includes('ã‚ªãƒ•') || lowerPrompt.includes('æ¶ˆã—'))) {
Â  Â  Â  Â  iotCommand = 'OFF';
Â  Â  }

Â  Â  if (iotCommand) {
Â  Â  Â  Â  // ğŸ’¡ ä¿®æ­£: ãƒ€ãƒŸãƒ¼ã§ã¯ãªãã€å®Ÿéš›ã®IoTã‚³ãƒãƒ³ãƒ‰é€ä¿¡é–¢æ•°ã‚’å‘¼ã³å‡ºã™
Â  Â  Â  Â  await sendIoTCommand(iotCommand);
Â  Â  Â  Â  return; 
Â  Â  }
Â  Â  
Â  Â  // 2. LLMå¿œç­”ç”Ÿæˆï¼ˆIoTã‚³ãƒãƒ³ãƒ‰ã§ãªã‹ã£ãŸå ´åˆï¼‰
Â  Â  await generateAndSpeakResponse(finalPrompt);
}


/* ---------- LLM (Gemini) API & TTS é€£æº - **ä¿®æ­£ç®‡æ‰€** ---------- */
async function generateAndSpeakResponse(prompt) {
Â  Â  status('Generating response (via FastAPI)...');
Â  Â  
Â  Â  // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€ŒAIå¿œç­”:ã€ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’è©±ã—ãŸå ´åˆã€ãã‚Œã‚’é™¤å¤–ã™ã‚‹
Â  Â  const cleanedPrompt = prompt.replace(/^ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”:\s*/, '').trim();
Â  Â  if (!cleanedPrompt) {
Â  Â  Â  Â  return; 
Â  Â  }

// Â  Â  // ğŸ’¡ Google APIã®ä»£ã‚ã‚Šã«ã€FastAPIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã™ã‚‹ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
// Â  Â  const payload = {
// Â  Â  Â  Â  prompt: cleanedPrompt,
// Â  Â  Â  Â  max_length: 1000 // ã‚µãƒ¼ãƒãƒ¼å´ã§å‡¦ç†
// Â  Â  };
const systemInstruction = "ã‚ãªãŸã¯ã€Œã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“ã€ã¨ã„ã†åå‰ã®KS-903model8800-a1-90dã¨ã„ã†éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ã€ç°¡æ½”ã‹ã¤ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚";

    const payload = {
        prompt: cleanedPrompt,
// Â  Â  Â  Â  max_length: 1000 // ã‚µãƒ¼ãƒãƒ¼å´ã§å‡¦ç†
        contents: [{ parts: [{ text: cleanedPrompt }] }],
        systemInstruction: { parts: [{ text: systemInstruction }] },
        tools: [{ "google_search": {} }], 
    };
Â  Â  
Â  Â  // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£… (FastAPIå‘¼ã³å‡ºã—ç”¨ã«èª¿æ•´)
Â  Â  const MAX_RETRIES = 3;
Â  Â  let responseText = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIã®KS-903model8800-a1-90då¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";

Â  Â  for (let i = 0; i < MAX_RETRIES; i++) {
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  // ğŸ’¡ ä¿®æ­£: æ¥ç¶šå…ˆã‚’FastAPIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«å¤‰æ›´
Â  Â  Â  Â  Â  Â  const response = await fetch(LLM_API_URL, {
Â  Â  Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json' },
Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify(payload)
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // 429 (ãƒ¬ãƒ¼ãƒˆåˆ¶é™) ã¯é€šå¸¸FastAPIå´ã§ã¯ç™ºç”Ÿã—ãªã„ãŒã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å‡¦ç†ã™ã‚‹
Â  Â  Â  Â  Â  Â  if (!response.ok) {
Â  Â  Â  Â  Â  Â  Â  Â  // FastAPIã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰è©³ç´°ã‚¨ãƒ©ãƒ¼ã‚’å–å¾—
Â  Â  Â  Â  Â  Â  Â  Â  const errorData = await response.json().catch(() => ({ detail: `HTTP ${response.status} Error.` }));
Â  Â  Â  Â  Â  Â  Â  Â  throw new Error(`FastAPI Error! Status: ${response.status}. Detail: ${errorData.detail}`);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const result = await response.json();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if (result && result.text) {
Â  Â  Â  Â  Â  Â  Â  Â  responseText = result.text;
Â  Â  Â  Â  Â  Â  Â  Â  break; // æˆåŠŸ
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â throw new Error("Empty response or invalid JSON structure from FastAPI.");
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  console.error(`FastAPI call error on attempt ${i + 1}:`, e);
Â  Â  Â  Â  Â  Â  if (i === MAX_RETRIES - 1) {
Â  Â  Â  Â  Â  Â  Â  Â  // æœ€å¾Œã®è©¦è¡Œã§å¤±æ•—ã—ãŸå ´åˆ
Â  Â  Â  Â  Â  Â  Â  Â  responseText = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIKS-903model8800-a1-90dã®å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Generaltebãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ (ãƒãƒ¼ãƒˆ8001) ã®å®Ÿè¡ŒçŠ¶æ…‹ã¨APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  // å†è©¦è¡Œã®ãŸã‚ã«å¾…æ©Ÿ
Â  Â  Â  Â  Â  Â  Â  Â  const delay = 2 ** i * 1000 + Math.random() * 500;
Â  Â  Â  Â  Â  Â  Â  Â  await new Promise(resolve => setTimeout(resolve, delay));
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  }

Â  Â  status('Speaking response...');
Â  Â  speak(responseText); 
}

/* ---------- TTS (Speech Synthesis) ---------- */
const synth = window.speechSynthesis;

function speak(text){ 
Â  Â  if(!text) return; 
Â  Â  
Â  Â  // é€£ç¶šå‘¼ã³å‡ºã—æŠ‘åˆ¶ã¨ã‚­ãƒ£ãƒ³ã‚»ãƒ«å‡¦ç†
Â  Â  if(synth.speaking) synth.cancel(); 
Â  Â  
Â  Â  // å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ transcriptBox ã«è¡¨ç¤º
Â  Â  transcriptBox.textContent = "ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”: " + text;
Â  Â  input.value = "ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”ä¸­...";

Â  Â  const u = new SpeechSynthesisUtterance(text); 
Â  Â  u.lang='ja-JP'; 
Â  Â  u.rate=1.0; 
Â  Â  u.onstart=()=>{ 
Â  Â  Â  Â  status('Speaking...'); 
Â  Â  Â  Â  input.value = "ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”ä¸­...";
Â  Â  }; 
Â  Â  u.onend=()=>{ 
Â  Â  Â  Â  // èª­ã¿ä¸Šã’çµ‚äº†å¾Œã€STTã®onendãƒ­ã‚¸ãƒƒã‚¯ã§å†ã‚¹ã‚¿ãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯çŠ¶æ…‹ã‚’æˆ»ã™
Â  Â  Â  Â  status('Ready to listen...'); 
Â  Â  Â  Â  input.value = "è©±ã—ã‹ã‘ã¦ãã ã•ã„...";
Â  Â  }; 
Â  Â  u.onerror = (e) => {
Â  Â  Â  Â  console.error('TTS error:', e);
Â  Â  Â  Â  status('TTS Error. Ready to listen...');
Â  Â  Â  Â  input.value = "è©±ã—ã‹ã‘ã¦ãã ã•ã„...";
Â  Â  };

Â  Â  synth.speak(u); 
}


/* ---------- UI ãƒˆã‚°ãƒ«æ©Ÿèƒ½ (ç”»é¢ã‚¿ãƒƒãƒ—) ---------- */
let uiVisible = true;
tapArea.addEventListener('click', (e) => {
Â  Â  // è¨˜å…¥æ¬„ã‚„ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã¸ã®ã‚¿ãƒƒãƒ—ã¯ç„¡è¦–ã™ã‚‹
Â  Â  if (e.target.closest('#controls') || e.target.closest('#transcript')) {
Â  Â  Â  Â  return;
Â  Â  }

Â  Â  uiVisible = !uiVisible;
Â  Â  if (uiVisible) {
Â  Â  Â  Â  ui.style.opacity = 1; // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
Â  Â  } else {
Â  Â  Â  Â  ui.style.opacity = 0; // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
Â  Â  }
});


/* ---------- Controls ---------- */
resetBtn.addEventListener('click', ()=>{ 
Â  Â  // STTã¨TTSã‚’å¼·åˆ¶åœæ­¢
Â  Â  if (recognition) {
Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  recognition = null;
Â  Â  }
Â  Â  if(synth.speaking) synth.cancel(); 

Â  Â  input.value=''; 
Â  Â  transcriptBox.textContent=''; 
Â  Â  
Â  Â  // å†åº¦éŒ²éŸ³ã‚’é–‹å§‹
Â  Â  initAudioAndSTT();
Â  Â  status('Reset. Listening...'); 
});


/* ---------- Start-up ---------- */
window.onload = function() {
Â  Â  // 1. èµ·å‹•æ™‚ã«ãƒã‚¤ã‚¯åˆæœŸåŒ–ã¨STTã‚’è‡ªå‹•ã§é–‹å§‹
Â  Â  initAudioAndSTT();

Â  Â  // 2. Waveformã®è¦–è¦šãƒ«ãƒ¼ãƒ—
Â  Â  (function loopCanvas(){
Â  Â  Â  Â  if(analyser){
Â  Â  Â  Â  Â  Â  // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
Â  Â  Â  Â  Â  Â  const bufferLen = analyser.frequencyBinCount; 
Â  Â  Â  Â  Â  Â  const data = new Float32Array(bufferLen);
Â  Â  Â  Â  Â  Â  analyser.getFloatTimeDomainData(data); 

Â  Â  Â  Â  Â  Â  ctx.clearRect(0,0,canvas.width,canvas.height);
Â  Â  Â  Â  Â  Â  ctx.beginPath();
Â  Â  Â  Â  Â  Â  const mid = canvas.height*0.55; 
Â  Â  Â  Â  Â  Â  const step = canvas.width / bufferLen;
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  let x = 0; 
Â  Â  Â  Â  Â  Â  for(let i=0;i<bufferLen;i++){ 
Â  Â  Â  Â  Â  Â  Â  Â  // èªè­˜ä¸­ã‹ã©ã†ã‹ã§æŒ¯å¹…ã‚’èª¿æ•´
Â  Â  Â  Â  Â  Â  Â  Â  const amp = isRecording ? 0.9 : 0.2; 
Â  Â  Â  Â  Â  Â  Â  Â  const y=mid + data[i]*mid*amp; 
Â  Â  Â  Â  Â  Â  Â  Â  x = i * step; 
Â  Â  Â  Â  Â  Â  Â  Â  if(i===0)ctx.moveTo(x,y);else ctx.lineTo(x,y) 
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  ctx.strokeStyle='rgba(0,230,255,0.9)'; ctx.lineWidth=2; ctx.stroke();
Â  Â  Â  Â  }
Â  Â  Â  Â  requestAnimationFrame(loopCanvas);
Â  Â  })();
};
// 3. Waveformã®è¦–è¦šãƒ«ãƒ¼ãƒ—
Â  Â  (function loopCanvas(){
Â  Â  Â  Â  if(analyser){
Â  Â  Â  Â  Â  Â  const bufferLen = analyser.fftSize; const data = new Float32Array(bufferLen);
Â  Â  Â  Â  Â  Â  analyser.getFloatTimeDomainData(data);
Â  Â  Â  Â  Â  Â  ctx.clearRect(0,0,canvas.width,canvas.height);
Â  Â  Â  Â  Â  Â  ctx.beginPath();
Â  Â  Â  Â  Â  Â  const mid = canvas.height*0.55; const step = canvas.width / bufferLen;
Â  Â  Â  Â  Â  Â  for(let i=0;i<bufferLen;i++){ 
Â  Â  Â  Â  Â  Â  Â  Â  // ğŸ’¡ æ³¢å½¢ã‚’ã‚ˆã‚Šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã«
Â  Â  Â  Â  Â  Â  Â  Â  const amp = isRecording ? 0.9 : 0.4;
Â  Â  Â  Â  Â  Â  Â  Â  const y=mid + data[i]*mid*amp; 
Â  Â  Â  Â  Â  Â  Â  Â  if(i===0)ctx.moveTo(x,y);else ctx.lineTo(x,y) 
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  ctx.strokeStyle='rgba(0,230,255,0.9)'; ctx.lineWidth=2; ctx.stroke();
Â  Â  Â  Â  }
Â  Â  Â  Â  requestAnimationFrame(loopCanvas);
Â  Â  })();
</script></body>
</html>